{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Custom Transformer to Add Time Features ===\n",
    "class TimeFeaturesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, time_column='Timestamp'):\n",
    "        self.time_column = time_column\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        df = X.copy()\n",
    "        df[self.time_column] = pd.to_datetime(df[self.time_column])\n",
    "        df['Hour'] = df[self.time_column].dt.hour\n",
    "        df['DayOfYear'] = df[self.time_column].dt.dayofyear\n",
    "        df['Month'] = df[self.time_column].dt.month\n",
    "        return df.drop(columns=[self.time_column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Custom Transformer to Drop Quality & Non-Feature Columns ===\n",
    "class DropColumns(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns_to_drop):\n",
    "        self.columns_to_drop = columns_to_drop\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.drop(columns=self.columns_to_drop, errors='ignore')\n",
    "\n",
    "# === Custom Transformer to Remove Outliers ===\n",
    "class OutlierRemover(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, threshold=3):\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Check if input is a pandas DataFrame or a NumPy array\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            df = X.copy()\n",
    "            z = np.abs((df - df.mean()) / df.std())\n",
    "            filtered_df = df[(z < self.threshold).all(axis=1)]\n",
    "            return filtered_df.reset_index(drop=True)\n",
    "        else:\n",
    "            # Handle NumPy array\n",
    "            X_mean = np.mean(X, axis=0)\n",
    "            X_std = np.std(X, axis=0)\n",
    "            z_scores = np.abs((X - X_mean) / (X_std + 1e-10))  # Add small epsilon to avoid division by zero\n",
    "            mask = (z_scores < self.threshold).all(axis=1)\n",
    "            return X[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === List of columns to drop based on your notebook ===\n",
    "columns_to_drop = [\n",
    "    'Record number', 'Chlorophyll [quality]', 'Temperature [quality]',\n",
    "    'Dissolved Oxygen [quality]', 'Dissolved Oxygen (%Saturation) [quality]',\n",
    "    'pH [quality]', 'Salinity [quality]', 'Specific Conductance [quality]',\n",
    "    'Turbidity [quality]'\n",
    "]\n",
    "\n",
    "# === Full Pipeline ===\n",
    "training_pipeline = Pipeline([\n",
    "    ('drop_columns', DropColumns(columns_to_drop=columns_to_drop)),\n",
    "    ('add_time_features', TimeFeaturesAdder()),\n",
    "    ('impute_missing', SimpleImputer(strategy='median')),\n",
    "    ('remove_outliers', OutlierRemover(threshold=3)),  # ✅ KEEP THIS HERE\n",
    "    ('scaling', StandardScaler()),\n",
    "    ('pca', PCA(n_components=0.95))\n",
    "])\n",
    "\n",
    "inference_pipeline = Pipeline([\n",
    "    ('drop_columns', DropColumns(columns_to_drop=columns_to_drop)),\n",
    "    ('add_time_features', TimeFeaturesAdder()),\n",
    "    ('impute_missing', SimpleImputer(strategy='median')),\n",
    "    # ❌ No outlier remover\n",
    "    ('scaling', StandardScaler()),\n",
    "    ('pca', PCA(n_components=0.95))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/pipeline_inference.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Make sure the folder exists\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Save both pipelines into the 'models' directory\n",
    "joblib.dump(training_pipeline, 'models/pipeline_training.pkl')\n",
    "joblib.dump(inference_pipeline, 'models/pipeline_inference.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
